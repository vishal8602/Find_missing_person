{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df81f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "def get_cropped_image_if_2_eyes(img):\n",
    "    #img = cv2.imread(image_path)\n",
    "    gray=None\n",
    "    try :\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    except: pass\n",
    "    if gray is not None  :\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            #if len(eyes) >= 2:\n",
    "            return roi_color\n",
    "    return None\n",
    "\n",
    "# #--------------------------------------wavelet transform--------------------------\n",
    "\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H\n",
    "\n",
    "\n",
    "# #--------------------------------------------------------------------------------------------------------------------------\n",
    "# #--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "\n",
    "#modules\n",
    "\n",
    "import pyrebase\n",
    "from pyrebase.pyrebase import storage \n",
    "import firebase_admin\n",
    "from firebase_admin import storage, credentials\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "#configuration \n",
    "\n",
    "firebaseConfig = {\n",
    "  'apiKey': \"AIzaSyDhgd3FaW3e3l3DJJ79eParkGJB-0UHjuc\",\n",
    "  'authDomain': \"findmissing-e2f89.firebaseapp.com\",\n",
    "  'projectId': \"findmissing-e2f89\",\n",
    "  'storageBucket': \"findmissing-e2f89.appspot.com\",\n",
    "  'databaseURL' :\"https://findmissing-e2f89-default-rtdb.europe-west1.firebasedatabase.app/\",\n",
    "  'messagingSenderId': \"221231936886\",\n",
    "  'appId': \"1:221231936886:web:f6164bf1e571bf14d8b657\",\n",
    "  'measurementId': \"G-4DEHRL9Z56\",\n",
    "  'serviceAccount': \"findmissing-e2f89-firebase-adminsdk-wm9zz-cdb4e0c510.json\"\n",
    "  \n",
    "}\n",
    "\n",
    "#firebase authentication\n",
    "\n",
    "firebase=pyrebase.initialize_app(firebaseConfig)\n",
    "\n",
    "auth=firebase.auth()\n",
    "\n",
    "#database\n",
    "\n",
    "db=firebase.database()\n",
    "storage=firebase.storage()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_person(img):\n",
    "             \n",
    "              import numpy as np\n",
    "              image=get_cropped_image_if_2_eyes(img)\n",
    "              \n",
    "              if(image is None):\n",
    "                \n",
    "                st.text(\"Not Able to crop that image Please Upload clear Image\")\n",
    "                col1,col2=st.columns(2)\n",
    "                with col1:\n",
    "                 if(st.button(\"If You Don't Have Any Other Image Continue with same image But chances of getting correct result will decreases\")):\n",
    "                      image=img\n",
    "                      X=[]\n",
    "                      y=[]\n",
    "\n",
    "                      scalled_raw_img = cv2.resize(image, (32, 32))\n",
    "                      st.image(scalled_raw_img,\"scalled_raw_img image\")\n",
    "                      img_har = w2d(image,'db1',5)\n",
    "                      print(type(scalled_raw_img))\n",
    "\n",
    "                      st.image(img_har,\"Wavelet transform of image\")\n",
    "                      scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "                      st.image(scalled_img_har,\"scalled_img_har image\")\n",
    "                      print(type(scalled_img_har))\n",
    "\n",
    "                      combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "                      # combined_img=np.array(combined_img)\n",
    "                      #st.image(combined_img,\"Combined image for feature extraction\")\n",
    "                      print(type(combined_img))\n",
    "                      X.append(combined_img)\n",
    "\n",
    "                      X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "\n",
    "                      import urllib.request, urllib.parse, urllib.error\n",
    "                      url = storage.child(\"name.txt\").get_url(None)\n",
    "                      text_file =urllib.request.urlopen(url).read()\n",
    "                      name=pickle.loads(text_file)\n",
    "\n",
    "                      url = storage.child(\"pipeSVM.pkl\").get_url(None)\n",
    "                      text_file =urllib.request.urlopen(url).read()\n",
    "                      pipeSVM=pickle.loads(text_file)\n",
    "\n",
    "        #               url = storage.child(\"pipeLOGistic.pkl\").get_url(None)\n",
    "        #               text_file =urllib.request.urlopen(url).read()\n",
    "        #               pipeLOGistic=pickle.loads(text_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                      ansSVM=pipeSVM.predict(X)\n",
    "                      st.text_area(\"SVM Match Found name of the Person is \",name[ansSVM[0]])\n",
    "        #             ansLOGistic=pipeLOGistic.predict(X)\n",
    "                with col2:    \n",
    "                    import pyautogui\n",
    "                    if st.button(\"New Image\"):\n",
    "                        pyautogui.hotkey(\"ctrl\",\"F5\")\n",
    "              else:\n",
    "                      st.image(image,\"cropped image\")\n",
    "                      X=[]\n",
    "                      y=[]\n",
    "\n",
    "                      scalled_raw_img = cv2.resize(image, (32, 32))\n",
    "                      st.image(scalled_raw_img,\"scalled_raw_img image\")\n",
    "                      img_har = w2d(image,'db1',5)\n",
    "                      print(type(scalled_raw_img))\n",
    "\n",
    "                      st.image(img_har,\"Wavelet transform of image\")\n",
    "                      scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "                      st.image(scalled_img_har,\"scalled_img_har image\")\n",
    "                      print(type(scalled_img_har))\n",
    "\n",
    "                      combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "                      # combined_img=np.array(combined_img)\n",
    "                      #st.image(combined_img,\"Combined image for feature extraction\")\n",
    "                      print(type(combined_img))\n",
    "                      X.append(combined_img)\n",
    "\n",
    "                      X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "\n",
    "                      import urllib.request, urllib.parse, urllib.error\n",
    "                      url = storage.child(\"name.txt\").get_url(None)\n",
    "                      text_file =urllib.request.urlopen(url).read()\n",
    "                      name=pickle.loads(text_file)\n",
    "\n",
    "                      url = storage.child(\"pipeSVM.pkl\").get_url(None)\n",
    "                      text_file =urllib.request.urlopen(url).read()\n",
    "                      pipeSVM=pickle.loads(text_file)\n",
    "\n",
    "        #               url = storage.child(\"pipeLOGistic.pkl\").get_url(None)\n",
    "        #               text_file =urllib.request.urlopen(url).read()\n",
    "        #               pipeLOGistic=pickle.loads(text_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                      ansSVM=pipeSVM.predict(X)\n",
    "                      st.text_area(\"SVM Match Found name of the Person is \",name[ansSVM[0]])\n",
    "                #             ansLOGistic=pipeLOGistic.predict(X)\n",
    "             \n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "               \n",
    "                   \n",
    "\n",
    "def report_person(image_list,name_report):\n",
    "            \n",
    "\n",
    "            import urllib.request, urllib.parse, urllib.error\n",
    "            \n",
    "            url = storage.child(\"x.txt\").get_url(None)\n",
    "            text_file =urllib.request.urlopen(url).read()\n",
    "            X=pickle.loads(text_file)\n",
    "\n",
    "\n",
    "          \n",
    "            url = storage.child(\"y.txt\").get_url(None)\n",
    "            text_file =urllib.request.urlopen(url).read()\n",
    "            Y=pickle.loads(text_file)\n",
    "\n",
    "\n",
    "           \n",
    "            url = storage.child(\"name.txt\").get_url(None)\n",
    "            text_file =urllib.request.urlopen(url).read()\n",
    "            name=pickle.loads(text_file)\n",
    "            \n",
    "         \n",
    "            \n",
    "            url = storage.child(\"pipeSVM.pkl\").get_url(None)\n",
    "            text_file =urllib.request.urlopen(url).read()\n",
    "            pipeSVM=pickle.loads(text_file)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             url = storage.child(\"pipeLOGistic.pkl\").get_url(None)\n",
    "#             text_file =urllib.request.urlopen(url).read()\n",
    "#             pipeLOGistic=pickle.loads(text_file)\n",
    "            \n",
    "           \n",
    "            st.header(\"Already register User Name with ID\")\n",
    "            new_name  = pd.DataFrame.from_records([name])\n",
    "            st.dataframe(new_name)\n",
    "            \n",
    "            \n",
    "            name[len(name)]=name_report\n",
    "            new_x=[]\n",
    "            count=0\n",
    "            \n",
    "            \n",
    "            st.text_area(\"TOTAL IMAGES TILL NOW \",len(X))\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "            \n",
    "            \n",
    "            SCORE1=pipeSVM.score(X_test, y_test)\n",
    "            SCORE1=float(SCORE1)\n",
    "            st.text_area(\"SCORE OF SVM BEFORE \",SCORE1)\n",
    "            \n",
    "            \n",
    "#             SCORE2=pipeLOGistic.score(X_test, y_test)\n",
    "#             SCORE2=float(SCORE2)\n",
    "#             st.text_area(\"SCORE OF LOGISTIC REGRESSION \",SCORE2)\n",
    "            \n",
    "            for i in image_list:\n",
    "#               st.image(i,\"before cropping\")\n",
    "              image=get_cropped_image_if_2_eyes(i)\n",
    "              count=count+1\n",
    "              #st.image(image,\"cropped image\")\n",
    "              \n",
    "          \n",
    "              scalled_raw_img = cv2.resize(image, (32, 32))\n",
    "              #st.image(scalled_raw_img,\"scalled_raw_img image\")\n",
    "\n",
    "              img_har = w2d(image,'db1',5)\n",
    "              #st.image(img_har,\"Wavelet transform of image\")\n",
    "\n",
    "              scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "              #st.image(scalled_img_har,\"scalled_img_har image\")\n",
    "              \n",
    "\n",
    "              combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "              new_x.append(combined_img)\n",
    "              Y.append(name[name_report])   \n",
    "            st.text_area(\"TOTAL NO OF IMAGES UPLOADED BY YOU\",count)\n",
    "           \n",
    "            new_x = np.array(new_x).reshape(len(new_x),4096).astype(float)\n",
    "            X=np.vstack((X,new_x))\n",
    "            X=np.array(X).reshape(len(X),4096).astype(float)\n",
    "            # Y=np.array(Y)\n",
    "#             print(\"len of x and y\",len(X),len(Y)) \n",
    "#             print(\"type o x and y\",type(X),type(Y))\n",
    "            # from sklearn.preprocessing import MultiLabelBinarizer  \n",
    "            # Y=MultiLabelBinarizer().fit_transform(Y)     \n",
    "             \n",
    "   \n",
    "           \n",
    "#             st.text_area(Y)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "            pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            SCORE=pipe.score(X_test, y_test)\n",
    "            SCORE=float(SCORE)\n",
    "            st.text_area(\"NEW SCORE of SVM NEWLY CREATED MODEL is\",SCORE)\n",
    "            \n",
    "            storage.delete('pipeSVM.pkl',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "            filename=pickle.dumps(pipeSVM)\n",
    "            chunk_size='262144'\n",
    "            storage.child('pipeSVM.pkl').put(filename,chunk_size)\n",
    "            \n",
    "            \n",
    "#             pipe=LogisticRegression(solver='liblinear',multi_class='auto')\n",
    "#             pipe.fit(X_train, y_train)\n",
    "#             SCORE=pipe.score(X_test, y_test)\n",
    "#             SCORE=float(SCORE)\n",
    "#             st.text_area(\"NEW SCORE of LOGISTIC REGRESSION NEWLY CREATED MODEL is\",SCORE)\n",
    "            \n",
    "            \n",
    "#             storage.delete('pipeLOGistic.pkl',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "#             filename=pickle.dumps(pipe)\n",
    "#             chunk_size='262144'\n",
    "#             storage.child('pipeSVM.pkl').put(filename,chunk_size)\n",
    "            \n",
    "            storage.delete('name.txt',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "            filename=pickle.dumps(name)\n",
    "            chunk_size='262144'\n",
    "            storage.child('name.txt').put(filename,chunk_size)\n",
    "            \n",
    "            storage.delete('x.txt',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "            filename=pickle.dumps(X)\n",
    "            chunk_size='262144'\n",
    "            storage.child('x.txt').put(filename,chunk_size)\n",
    "            \n",
    "            storage.delete('y.txt',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "            filename=pickle.dumps(Y)\n",
    "            chunk_size='262144'\n",
    "            storage.child('y.txt').put(filename,chunk_size)\n",
    "            \n",
    "\n",
    "if(st.button(\"Upload Model\")):\n",
    "    storage.child('pipeSVM.pkl').put('pipeSVM.pkl')\n",
    "\n",
    "\n",
    "st.title('Find Missing Person APP')\n",
    "option=st.sidebar.selectbox(\"Menu\",(\"Home\",\"Login\",\"Sign Up\",\"Find_Missing_Person\",\"Report_Missing_Person\",\"Register Users\"))\n",
    "\n",
    "\n",
    "if(option==\"Home\"):\n",
    "     st.header(\"Welcome !! We are here to help you in finding missing person\")\n",
    "\n",
    "\n",
    "elif(option==\"Login\"):\n",
    "\n",
    "    st.header(\"Login Page\")\n",
    "    email=st.text_input(\"Username\")\n",
    "    password=st.text_input(\"Password\" ,type=\"password\")\n",
    "    # create_usertable()\n",
    "    if(st.button(\"Login\") ):\n",
    "      try:\n",
    "        user=auth.sign_in_with_email_and_password(email, password)\n",
    "        st.success(\"Logged in succesfully\")\n",
    "        st.balloons()\n",
    "      except:\n",
    "         st.warning(\"Username Password Not valid\")\n",
    "\n",
    "elif(option==\"Sign Up\"):\n",
    "    st.header(\"Sign Up Page\")\n",
    "    email=st.text_input(\"Email\",value='Default')\n",
    "    password=st.text_input(\"Password\",type=\"password\")\n",
    "    if(st.button(\"SignUp\")):\n",
    "        \n",
    "        try:\n",
    "          user=auth.create_user_with_email_and_password(email,password)\n",
    "          st.success(\"Sign Up succesfully Please select login to login\")\n",
    "          st.balloons()   \n",
    "        except:\n",
    "          st.warning(\"User Already Register\")\n",
    "\n",
    "elif(option==\"Find_Missing_Person\"):\n",
    "      st.header(\"Find Missing Person\")\n",
    "      st.text_input(\"Name of person\")\n",
    "      st.text_input(\"Age\")\n",
    "      input_image=st.file_uploader(\"Upload Image Of Missing Person\")\n",
    "      if(input_image):\n",
    "        from PIL import Image\n",
    "        image=Image.open(input_image)\n",
    "        image=np.array(image)\n",
    "        st.header(\"Image Upaloded Succesfully\")\n",
    "        st.image(image,\"uploaded image\")\n",
    "        find_person(image)\n",
    "\n",
    "\n",
    "\n",
    "elif(option==\"Report_Missing_Person\"):\n",
    "      st.header(\"Report_Missing_Person\")\n",
    "      name=st.text_input(\"Name of person\")\n",
    "      age=st.text_input(\"Age\")\n",
    "      st.text(\"Please Upload at Least more than 5 image of Reporting Person size Must >=1MB\")\n",
    "      input_image=st.file_uploader(\"Upload Image Person\",accept_multiple_files=True)\n",
    "      new_list=[]\n",
    "      if(input_image):\n",
    "        from PIL import Image\n",
    "        for i in input_image:\n",
    "              image=Image.open(i)\n",
    "              image=np.array(image)\n",
    "              new_list.append(image)\n",
    "        report_person(new_list,name)\n",
    "\n",
    "elif(option==\"Register Users\"):\n",
    "     import urllib.request, urllib.parse, urllib.error\n",
    "     url = storage.child(\"name.txt\").get_url(None)\n",
    "     text_file =urllib.request.urlopen(url).read()\n",
    "     name=pickle.loads(text_file)\n",
    "     st.table([name])\n",
    "     \n",
    "# ------------testing\n",
    "\n",
    "# if(st.button(\"For deleting the old model\")):\n",
    "#     storage.delete(\"Vishal\",\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# !streamlit  run app.py & npx localtunnel --port 8501\n",
    "# !pip install streamlit pyrebase\n",
    "#!pip install firebase-admin\n",
    "# import streamlit as st\n",
    "# st.title(\"Learning\")\n",
    "# st.header(\"Load image\")\n",
    "# input_image=st.file_uploader(\"Select image\")\n",
    "# from PIL import Image\n",
    "# if(input_image):\n",
    "  \n",
    "#   image=Image.open(input_image)\n",
    "#   st.image(image)\n",
    "#   print(type(image))\n",
    "#   image=np.array(image)\n",
    "#   image=get_cropped_image_if_2_eyes(image)\n",
    "#   print(type(image))\n",
    "#   plt.imshow(image)\n",
    "#   st.image(image,\"cropped image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07490d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0149e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745731d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ec9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3aabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265fb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cdc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34c9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd1950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4ae85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46a2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray=None\n",
    "    try :\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    except: pass\n",
    "    if gray is not None  :\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            if len(eyes) >= 2:\n",
    "                return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e7595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824049f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2958801",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./dataset/\"\n",
    "path_to_cr_data = \"./dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7eaeb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776d019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.53.tar.gz (59 kB)\n",
      "Collecting pymsgbox\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting PyTweening>=1.0.1\n",
      "  Downloading pytweening-1.0.4.tar.gz (14 kB)\n",
      "Collecting pyscreeze>=0.1.21\n",
      "  Downloading PyScreeze-0.1.28.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting pygetwindow>=0.0.5\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "Collecting mouseinfo\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "Collecting pyrect\n",
      "  Downloading PyRect-0.1.4.tar.gz (15 kB)\n",
      "Collecting pyperclip\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, PyTweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "  Building wheel for pyautogui (setup.py): started\n",
      "  Building wheel for pyautogui (setup.py): finished with status 'done'\n",
      "  Created wheel for pyautogui: filename=PyAutoGUI-0.9.53-py3-none-any.whl size=36613 sha256=56a4c0bc6f3e8b6cac790841de94e98d803b26eddcc88fa0560367039cc1aaad\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\d8\\97\\e4\\d2edca92a87d3b5fbfb527264750a17b4ba297b9a7cab6e67f\n",
      "  Building wheel for pygetwindow (setup.py): started\n",
      "  Building wheel for pygetwindow (setup.py): finished with status 'done'\n",
      "  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11080 sha256=33f9a097538f207cd601bda371d0fab2003a422812d916eb59874ee577b2d8a1\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\44\\ab\\20\\423c3a444793767e4e41f8377bc902f77bee212e68dcce85a5\n",
      "  Building wheel for pyscreeze (PEP 517): started\n",
      "  Building wheel for pyscreeze (PEP 517): finished with status 'done'\n",
      "  Created wheel for pyscreeze: filename=PyScreeze-0.1.28-py3-none-any.whl size=13021 sha256=ba2da4af12d0bc8fd0bf2f39f4156272d0d5b30d62fdfeb0b68fafe47c291b74\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\a2\\5b\\86\\99f1d8fac5d92de0ccb3f0d4ad15e3f4278baf75a9b0f20b93\n",
      "  Building wheel for PyTweening (setup.py): started\n",
      "  Building wheel for PyTweening (setup.py): finished with status 'done'\n",
      "  Created wheel for PyTweening: filename=pytweening-1.0.4-py3-none-any.whl size=5854 sha256=e8521c652d7cfbdd3b029c3db9c47f137be374e2cd3f0639b0b4f10abf47c2dc\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\a4\\5d\\d2\\ba4c8f82163233ffaadcf383c1e34d7d92635d357d13e7b78d\n",
      "  Building wheel for mouseinfo (setup.py): started\n",
      "  Building wheel for mouseinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10906 sha256=23da18db1eee513c758f34deab67024991d35abfc66af15c801ca8dcf9bd2cba\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\61\\73\\b9\\6fb1131ab36e650206e3aa0ad7a68907b41b32ac2d4f75f543\n",
      "  Building wheel for pymsgbox (PEP 517): started\n",
      "  Building wheel for pymsgbox (PEP 517): finished with status 'done'\n",
      "  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7420 sha256=ad93eb738b0829d4dc9a2d897bfb061d0345342a34688f1220ea8bf4e9b87aca\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\7f\\13\\8c\\584c519464297d9637f9cd29fd1dcdf55e2a2cab225c76a2db\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=de46d24bdff6fe0f4b18bb230e8f057c6b8035980be56d1d3eba6d12cab518eb\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\0c\\09\\9e\\49e21a6840ef7955b06d47394afef0058f0378c0914e48b8b8\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.1.4-py2.py3-none-any.whl size=9547 sha256=495bbfd7895eee13ef804ed46d4f4dee291057c33f2fe9e0ab48d12859f1772c\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\0e\\d4\\c5\\b7f7be24ac0a168fd03d08afcc7c8928ef05cc1e319d1c136b\n",
      "Successfully built pyautogui pygetwindow pyscreeze PyTweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: pyrect, pyperclip, PyTweening, pyscreeze, pymsgbox, pygetwindow, mouseinfo, pyautogui\n",
      "Successfully installed PyTweening-1.0.4 mouseinfo-0.1.3 pyautogui-0.9.53 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.1.4 pyscreeze-0.1.28\n",
      "Collecting pyautogui\n",
      "  Using cached PyAutoGUI-0.9.53-py3-none-any.whl\n",
      "Collecting pymsgbox\n",
      "  Using cached PyMsgBox-1.0.9-py3-none-any.whl\n",
      "Collecting pyscreeze>=0.1.21\n",
      "  Using cached PyScreeze-0.1.28-py3-none-any.whl\n",
      "Collecting PyTweening>=1.0.1\n",
      "  Using cached pytweening-1.0.4-py3-none-any.whl\n",
      "Collecting mouseinfo\n",
      "  Using cached MouseInfo-0.1.3-py3-none-any.whl\n",
      "Collecting pygetwindow>=0.0.5\n",
      "  Using cached PyGetWindow-0.0.9-py3-none-any.whl\n",
      "Collecting pyrect\n",
      "  Using cached PyRect-0.1.4.tar.gz (15 kB)\n",
      "Collecting pyperclip\n",
      "  Using cached pyperclip-1.8.2-py3-none-any.whl\n",
      "Building wheels for collected packages: pyrect\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.1.4-py2.py3-none-any.whl size=9547 sha256=bb30f0a60f59d61697365b8e641273f76acd3608eebb39c991e8bd38f5188c3b\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\0e\\d4\\c5\\b7f7be24ac0a168fd03d08afcc7c8928ef05cc1e319d1c136b\n",
      "Successfully built pyrect\n",
      "Installing collected packages: pyrect, pyperclip, PyTweening, pyscreeze, pymsgbox, pygetwindow, mouseinfo, pyautogui\n",
      "Successfully installed PyTweening-1.0.4 mouseinfo-0.1.3 pyautogui-0.9.53 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.1.4 pyscreeze-0.1.28\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25e53dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_to_cr_data):\n",
    "     shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901b4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cropped images in folder:  ./dataset/cropped/Aishwarya Rai\n",
      "Generating cropped images in folder:  ./dataset/cropped/Narendra Modi\n",
      "Generating cropped images in folder:  ./dataset/cropped/Virat Kohli\n"
     ]
    }
   ],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c524fd",
   "metadata": {},
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a361e0d",
   "metadata": {},
   "source": [
    "# wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfad6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0220c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cropped_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14008/3310248565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mim_har\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'db1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_har\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cropped_image' is not defined"
     ]
    }
   ],
   "source": [
    "im_har = w2d(cropped_image,'db1',5)\n",
    "plt.imshow(im_har, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c37931fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Aishwarya Rai', 1: 'Narendra Modi', 2: 'Virat Kohli'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[count] = celebrity_name\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e28669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "350afeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fe9b28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 4096)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaaff29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd84c36b",
   "metadata": {},
   "source": [
    "# Data cleaning process is done. Now we are ready to train our model We will    use SVM with rbf kernel tuned with heuristic finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908eef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "542ae07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361702127659575"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf6259ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.94        47\n",
      "   macro avg       0.95      0.92      0.93        47\n",
      "weighted avg       0.94      0.94      0.94        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08f398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aca0251",
   "metadata": {},
   "source": [
    "# Let's use GridSearch to try out different models with different paramets. Goal is to come up with best modle with best fine tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df474f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebb7205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ee191a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb104fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.921429   \n",
       "1        random_forest    0.828571   \n",
       "2  logistic_regression    0.878571   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                  {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d46134a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9787234042553191"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5154cb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936170212765957"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96c69e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361702127659575"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_estimators['logistic_regression'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13b35a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95b66f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0],\n",
       "       [ 0, 12,  0],\n",
       "       [ 1,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d175e5fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14008/1303397302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Truth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0f1982f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Aishwarya Rai', 1: 'Narendra Modi', 2: 'Virat Kohli'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6cfd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"pipeSVM.pkl\"\n",
    "file=open(filename,'wb')\n",
    "pickle.dump(best_estimators['svm'],file)\n",
    "#             storage.delete('pipeSVM.pkl',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "#             storage.child('pipeSVM.pkl').put('pipeSVM.pkl')\n",
    "            \n",
    "filename=\"x.txt\"\n",
    "file=open(filename,'wb')\n",
    "pickle.dump(X,file)\n",
    "#             storage.delete('x.txt',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "#             storage.child('x.txt').put('x.txt')\n",
    "            \n",
    "filename=\"y.txt\"\n",
    "file=open(filename,'wb')\n",
    "pickle.dump(y,file)\n",
    "#             storage.delete('y.txt',\"https://firebasestorage.googleapis.com/v0/b/findmissing-e2f89.appspot.com/o/pipeSVM.pkl?alt=media&token=64756737-fdca-4e3d-8517-d205a1476bab\")\n",
    "#             storage.child('y.txt').put('y.txt')\n",
    "            \n",
    "filename=\"name.txt\"\n",
    "file=open(filename,'wb')\n",
    "pickle.dump(class_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "756ca4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"pipeLOGistic.pkl\"\n",
    "file=open(filename,'wb')\n",
    "pickle.dump(best_estimators['logistic_regression'],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736200e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
